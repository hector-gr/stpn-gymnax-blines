# STPN Jax

This repository implements the Short-Term Plasticity Neuron (STPN) in Jax, and tests it in gymnax benchmark. It also implements LSTM PPO in gymnax.

STPN was presented in [this ICML 2022 paper](https://proceedings.mlr.press/v162/rodriguez22b.html), and was implemente in pytorch in [this github repository](https://github.com/NeuromorphicComputing/stpn).

![stpn lstm MetaMaze-misc](docs/MetaMaze-misc-LSTM_STPN.png)

## Abstract
Short-term plasticity (STP) is a mechanism that stores decaying memories in synapses of the cerebral cortex. In computing practice, STP has been used, but mostly in the niche of spiking neurons, even though theory predicts that it is the optimal solution to certain dynamic tasks. Here we present a new type of recurrent neural unit, the STP Neuron (STPN), which indeed turns out strikingly powerful. Its key mechanism is that synapses have a state, propagated through time by a self-recurrent connection-within-the-synapse. This formulation enables training the plasticity with backpropagation through time, resulting in a form of learning to learn and forget in the short term. The STPN outperforms all tested alternatives, i.e. RNNs, LSTMs, other models with fast weights, and differentiable plasticity. We confirm this in both supervised and reinforcement learning (RL), and in tasks such as Associative Retrieval, Maze Exploration, Atari video games, and MuJoCo robotics. Moreover, we calculate that, in neuromorphic or biological circuits, the STPN minimizes energy consumption across models, as it depresses individual synapses dynamically. Based on these, biological STP may have been a strong evolutionary attractor that maximizes both efficiency and computational power. The STPN now brings these neuromorphic advantages also to a broad spectrum of machine learning practice.  Code is available in https://github.com/NeuromorphicComputing/stpn.

Below is the original gymnax readme.


________

# Training & Speed Evaluation Tools for [`gymnax`](https://github.com/RobertTLange/gymnax)

<a href="https://github.com/RobertTLange/gymnax-blines/blob/main/docs/logo.png?raw=true"><img src="https://github.com/RobertTLange/gymnax-blines/blob/main/docs/logo.png?raw=true" width="215" align="right" /></a>


In this repository we provide training pipelines for [`gymnax`](https://github.com/RobertTLange/gymnax) agents in JAX. Furthermore, you can use the utilities to speed benchmark step transitions and to visualize trained agent checkpoints. Install all required dependencies via:

```
pip install -r requirements.txt
```

## Accelerated Training of Agents with [`gymnax`](https://github.com/RobertTLange/gymnax)

We provide training routines and the corresponding checkpoints for both Evolution Strategies (mostly OpenES using [`evosax`](https://github.com/RobertTLange/evosax) and PPO (using an adaptation of @bmazoure's [implementation](https://github.com/bmazoure/ppo_jax)). You can train the agents as follows: 

```
python train.py -config agents/<env_name>/ppo.yaml
python train.py -config agents/<env_name>/es.yaml
```

This will store checkpoints and training logs as `pkl` in `agents/<env_name>/ppo.pkl`. Collect all training runs sequentially via:

```
bash exec.sh train
```

![](docs/lcurves.png)

## Visualization of [`gymnax`](https://github.com/RobertTLange/gymnax) Environment Rollouts

You can also generate GIF visualizations of the trained agent's behaviour as follows:

```
python visualize.py -env <env_name> -train <{es/ppo}>
```

Collect all visualizations sequentially via:

```
bash exec.sh visualize
```

Note that we do not support visualizations for most behavior suite environments, since they do not lend themselves to visual display (e.g. markov reward process, etc.).

|  |  |  |  | 
| --- | --- | --- | --- |
| ![](docs/Pendulum-v1.gif) | ![](docs/Acrobot-v1.gif)  | ![](docs/CartPole-v1.gif) | ![](docs/MountainCarContinuous-v0.gif) |
| ![](docs/Asterix-MinAtar.gif) | ![](docs/Breakout-MinAtar.gif)  | ![](docs/Freeway-MinAtar.gif) | ![](docs/SpaceInvaders-MinAtar.gif) |
| ![](docs/Catch-bsuite.gif) | ![](docs/FourRooms-misc.gif)  | ![](docs/MetaMaze-misc.gif) | ![](docs/PointRobot-misc.gif) |

## Speed Up Evaluation for [`gymnax`](https://github.com/RobertTLange/gymnax) Environments

Finally, we provide simple tools for benchmarking the speed of step transitions on different hardware (CPU, GPU, TPU). For a specific environment the speed estimates can be obtained as follows:

```
python speed.py -env <env_name> --use_gpu --use_network --num_envs 10
```

Collect all speed estimates sequentially via:

```
bash exec.sh speed
```

![](docs/speed.png)

For each environment we estimate the seconds required to execute 1 Mio steps on various hardware and for both random (R)/neural network (N) policies. We report the mean over 10 independent runs:

| Environment Name | `np` <br /> CPU <br /> 10 Envs | `jax` <br /> CPU <br /> 10 Envs | `np` <br /> CPU <br /> 40 Envs | `jax` <br /> CPU <br /> 40 Envs | `jax` <br /> 2080Ti <br /> 2k Envs | `jax` <br /> A100 <br /> 2k Envs |
| --- | --- | --- | --- | --- | --- | --- | 
| [`Acrobot-v1`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/classic_control/acrobot.py) | R: 72 <br /> N: 118 | R: 1.16 <br /> N: 2.90 | R: 66 <br /> N: 77.2 | R: 1.03 <br /> N: 2.3 | R: 0.06 <br /> N: 0.08 | R: 0.07 <br /> N: 0.09
| [`Pendulum-v1`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/classic_control/pendulum.py) | R: 139 <br /> N: 118 | R: 0.41 <br /> N: 1.41 | R: 118 <br /> N: 70 | R: 0.32 <br /> N: 1.07 | R: 0.07 <br /> N: 0.09 | R: 0.07 <br /> N: 0.10
| [`CartPole-v1`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/classic_control/cartpole.py) | R: 46 <br /> N: 94 | R: 0.43 <br /> N: 1.42 | R: 45 <br /> N: 51 | R: 0.49 <br /> N: 0.98 | R: 0.06 <br /> N: 0.08 | R: 0.05 <br /> N: 0.08
| [`MountainCar-v0`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/classic_control/mountain_car.py) | R: 48 <br /> N: 105 | R: 0.53 <br /> N: 1.49 | R: 54 <br /> N: 57 | R: 0.39 <br /> N: 1.03 | R: 0.06 <br /> N: 0.09 | R: 0.07 <br /> N: 0.09
| [`MountainCarContinuous-v0`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/classic_control/continuous_mountain_car.py) | R: 117 <br /> N: 99 | R: 0.34 <br /> N: 1.11 | R: 98 <br /> N: 53 | R: 0.28 <br /> N: 0.85 | R: 0.09 <br /> N: 0.12 | R: 0.09 <br /> N: 0.12
|  |  |  |  |  |  |  |  |
| [`Asterix-MinAtar`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/minatar/asterix.py) | R: 62.95 <br /> N: 142.21 | R: 5.49 <br /> N: 20.15 | R: 55.08 <br /> N: 73.16 | R: 5.86 <br /> N: 22.46 | R: 0.89 <br /> N: 0.96 | R: 0.92 <br /> N: 0.98
| [`Breakout-MinAtar`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/minatar/breakout.py) | R: 49.35 <br /> N: 125.65 | R: 2.41 <br /> N: 13.70 | R: 48.30 <br /> N: 67.20 | R: 2.33 <br /> N: 13.93 | R: 0.20 <br /> N: 0.30 | R: 0.19 <br /> N: 0.26
| [`Freeway-MinAtar`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/minatar/freeway.py) | R: 49.91 <br /> N: 141.63 | R: 26.35 <br /> N: 74.02 | R: 50.04 <br /> N: 72.59 | R: 26.25 <br /> N: 53.66 | R: 1.17 <br /> N: 1.30 | R: 0.87 <br /> N: 0.95
| [`SpaceInvaders-MinAtar`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/minatar/space_invaders.py) | R: 65.58 <br /> N: 170.29 | R: 12.73 <br /> N: 33.51 | R: 69.24 <br /> N: 105.27 | R: 14.37 <br /> N: 30.09 | R: 0.35 <br /> N: 0.46 | R: 0.33 <br /> N: 0.39
|  |  |  |  |  |  |  |  |
| [`Catch-bsuite`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/bsuite/catch.py) | - | R: 0.99 <br /> N: 2.37 | - | R: 0.87 <br /> N: 1.82 | R: 0.17 <br /> N: 0.21 | R: 0.15 <br /> N: 0.21
| [`DeepSea-bsuite`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/bsuite/deep_sea.py) | - | R: 0.84 <br /> N: 1.97 | - | R: 1.04 <br /> N: 1.61 | R: 0.27 <br /> N: 0.33 | R: 0.22 <br /> N: 0.36
| [`MemoryChain-bsuite`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/bsuite/memory_chain.py) | - | R: 0.43 <br /> N: 1.46 | - | R: 0.37 <br /> N: 1.11 | R: 0.14 <br /> N: 0.21 | R: 0.13 <br /> N: 0.19
| [`UmbrellaChain-bsuite`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/bsuite/umbrella_chain.py) | - | R: 0.64 <br /> N: 1.82 | - | R: 0.48 <br /> N: 1.28 | R: 0.08 <br /> N: 0.11 | R: 0.08 <br /> N: 0.12
| [`DiscountingChain-bsuite`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/bsuite/discounting_chain.py) | - | R: 0.33 <br /> N: 1.32 | - | R: 0.21 <br /> N: 0.88 | R: 0.06 <br /> N: 0.07 | R: 0.06 <br /> N: 0.08
|  |  |  |  |  |  |  |  |
| [`FourRooms-misc`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/misc/rooms.py) | - | R: 3.12 <br /> N: 5.43 | - | R: 2.81 <br /> N: 4.6 | R: 0.09 <br /> N: 0.10 | R: 0.07 <br /> N: 0.10
| [`MetaMaze-misc`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/misc/meta_maze.py) | - | R: 0.80 <br /> N: 2.24 | - | R: 0.76 <br /> N: 1.69 | R: 0.09 <br /> N: 0.11 | R: 0.09 <br /> N: 0.12
| [`PointRobot-misc`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/misc/point_robot.py) | - | R: 0.84 <br /> N: 2.04 | - | R: 0.65 <br /> N: 1.31 | R: 0.08 <br /> N: 0.09 | R: 0.08 <br /> N: 0.10
| [`BernoulliBandit-misc`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/misc/bernoulli_bandit.py) | - | R: 0.54 <br /> N: 1.61 | - | R: 0.42 <br /> N: 0.97 | R: 0.07 <br /> N: 0.10 | R: 0.08 <br /> N: 0.11
| [`GaussianBandit-misc`](https://github.com/RobertTLange/gymnax/blob/main/gymnax/environments/misc/gaussian_bandit.py) | - | R: 0.56 <br /> N: 1.49 | - | R: 0.58 <br /> N: 0.89 | R: 0.05 <br /> N: 0.08 | R: 0.07 <br /> N: 0.09

TPU v3-8 comparisons will follow once I (or you?) find the time and resources ðŸ¤—